# Bibliotecas de Python
from fastapi import FastAPI, HTTPException
import uvicorn
from pydantic import BaseModel

from huggingface_hub import InferenceClient
from langchain_huggingface import HuggingFaceEndpoint
from langchain.prompts import PromptTemplate

from dotenv import load_dotenv
import os

import pymysql

''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Cargando mi llave personal de la API de HuggingFace:
load_dotenv(dotenv_path="Material_sensible/contrase√±a_api.env")

#Seleccionando la llave:
huggingface_api_key = os.getenv("HUGGINGFACE_API_KEY")

if not huggingface_api_key:
    raise ValueError("La clave API de Hugging Face no se carg√≥. Verifica el archivo contrase√±a.env.")

#Conexi√≥n con la api (LLM) de Hugging Face ya con la llave cargada:
client = InferenceClient(api_key=huggingface_api_key)




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Conexi√≥n con la DataBase de AWS
#Cargar las variables del archivo .env
load_dotenv(dotenv_path="Material_sensible/contrase√±a_database.env")

def connect_to_database():
    # Recuperar las variables de entorno del archivo .env
    host = os.getenv("DB_HOST")
    username = os.getenv("DB_USER")
    password = os.getenv("DB_PASSWORD")
    port = int(os.getenv("DB_PORT"))
    database = os.getenv("DB_NAME")

    try:
        
        connection = pymysql.connect(
            host=host,
            user=username,
            password=password,
            port=port,
            cursorclass=pymysql.cursors.DictCursor)

        print("Conexi√≥n exitosa a la base de datos.")

        connection.close()

    except pymysql.MySQLError as e:
        print(f"Error al conectarse a la base de datos: {e}")

#Realizar la conexi√≥n
connect_to_database()

#Generando la FastAPI
app = FastAPI()




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Creaci√≥n de la clase de "recetas"
#Creaci√≥n de la clase de "problemas culinarios"
#Creaci√≥n de las clases de "Conversiones"
#Creaci√≥n de las clases de"Temporadas y Pa√≠ses"
#Creaci√≥n de la clase de "Condici√≥n"

class GenerateRecipeRequest(BaseModel):
    ingredients: list[str]  #Lista de ingredientes

class KitchenProblemRequest(BaseModel):
    issue: str  #Tipo de problema (salado, picante, √°cido, etc.)

class ConversionRequest(BaseModel):
    quantity: float  #Cantidad que se desea convertir
    from_unit: str  #Unidad de origen (por ejemplo, "taza", "cucharada")
    to_unit: str  #Unidad de destino (por ejemplo, "gramos", "ml")

class SeasonalFoodRequest(BaseModel):
    season: str  #Estaci√≥n del a√±o: "primavera", "verano", "oto√±o", "invierno"
    country: str  #Pa√≠s: por ejemplo, "M√©xico", "Espa√±a"

class HealthConditionRequest(BaseModel):
    condition: str  #Condici√≥n del usuario (por ejemplo, "cel√≠aco", "intolerancia a la lactosa", "diabetes")




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
# Bienvenida a la p√°gina
@app.get("/")
async def home():
    return {"message": """
                    ¬°Bienvenidos a Tu Chef Virtual, donde el sabor cobra vida! üç≥‚ú®
                    
                    ¬øTe has quedado sin ideas para cocinar? ¬°No te preocupes! Con nuestra API personalizada, puedes:

                    üç¥ **Generar recetas**: Introduce una lista de ingredientes y nuestro chef virtual crear√° una receta deliciosa para ti. ¬°Perfecta para esos d√≠as en los que no sabes qu√© cocinar! 

                    üî• **Resolver problemas de cocina**: ¬øTu comida est√° demasiado salada, picante o √°cida? Dinos el problema y te damos la soluci√≥n para que no se eche a perder. üçΩÔ∏è

                    üßë‚Äçüç≥ **Conversi√≥n de medidas**: ¬øNo sabes cu√°ntos gramos tiene una taza de harina o cu√°ntos mililitros en una cucharada sopera? ¬°Aqu√≠ te lo calculamos!

                    üåø **Comidas seg√∫n temporada**: Introduce una estaci√≥n del a√±o y un pa√≠s, y te sugerimos platos de temporada que puedes preparar con ingredientes frescos.

                    üßë‚Äç‚öïÔ∏è **Alergias y enfermedades**: Si tienes alguna condici√≥n de salud como celiaqu√≠a, intolerancia a la lactosa o diabetes, te recomendamos qu√© alimentos evitar y qu√© alternativas usar.

                    Con nosotros, tu cocina ser√° m√°s f√°cil, creativa y saludable. ¬°Deja que tu chef virtual te gu√≠e en cada paso!

                    ¬øListo para cocinar con estilo? ¬°Comencemos juntos! üç¥
                   """
    }



''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Recetario
@app.post("/recetas/")
async def generate_recipe(request: GenerateRecipeRequest):
    ingredients = request.ingredients.lower() # Convertir a min√∫sculas para consistencia

    if len(ingredients) < 3:
        raise HTTPException(
            status_code=400, detail="Debes proporcionar almenos 3 ingredientes.")

    try:
        #Configuraci√≥n del modelo:
        llm = HuggingFaceEndpoint(endpoint_url="https://api-inference.huggingface.co/models/microsoft/Phi-3.5-mini-instruct",  # Modelo
                                  huggingfacehub_api_token=huggingface_api_key,  # Contrase√±a
                                  temperature=0.7,  # Precisi√≥n
                                  max_length=300)  # Tokens
        
        #Detallamos el prompt:
        prompt = PromptTemplate(input_variables=["ingredients_list"],
                                template="""
                                            Eres un chef experto en crear recetas cl√°sicas y deliciosas.
                                            Dada la siguiente lista de ingredientes: {ingredients_list},
                                            crea un plato t√≠pico. Describe brevemente el nombre del plato, 
                                            los pasos para prepararlo y un consejo especial para mejorar su sabor.
                                        """)

        #Generaci√≥n de la respuesta respecto al prompt:
        formatted_prompt = prompt.format(ingredients_list=", ".join(ingredients))
        respuesta = llm.invoke(formatted_prompt)

        # Devuelve la respuesta generada
        return {"recipe": respuesta}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ejemplo de uso
# {
#   "ingredients": ["lechuga", "tomate", "atun", "maiz", "aceite"]
# }



''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Solucionario
@app.post("/problemas_cocina/")
async def solve_kitchen_problem(request: KitchenProblemRequest):
    issue = request.issue.lower()  

    try:
        llm = HuggingFaceEndpoint(endpoint_url="https://api-inference.huggingface.co/models/microsoft/Phi-3.5-mini-instruct",  
                                  huggingfacehub_api_token=huggingface_api_key, 
                                  temperature=0.7,  
                                  max_length=300)  

        prompt = PromptTemplate(input_variables=["issue", "ingredient"],
                                template="""
                                            Eres un chef experimentado que ayuda a resolver problemas de cocina.
                                            Si el plato est√° {issue}, ¬øqu√© se debe hacer para solucionar el problema?
                                            Dar an√≠mos con el problema.
                                            Solo en caso de que no haya soluci√≥n proponer un plato de cocinado r√°pido.
                                         """)

        formatted_prompt = prompt.format(issue=issue)
        respuesta = llm.invoke(formatted_prompt)  

        return {"solution": respuesta}

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Ejemplo de uso:
# {
#   "issue": "salado",
# }




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Conversionario:
@app.post("/conversiones/")
async def convert_measurements(request: ConversionRequest):
    quantity = request.quantity
    from_unit = request.from_unit.lower()
    to_unit = request.to_unit.lower()

    try:

        llm = HuggingFaceEndpoint(
            endpoint_url="https://api-inference.huggingface.co/models/microsoft/Phi-3.5-mini-instruct",  
            huggingfacehub_api_token=huggingface_api_key,
            temperature=0.7,
            max_length=300
        )

        prompt = PromptTemplate(input_variables=["quantity", "from_unit", "to_unit"],
                                template="""
                                            Tienes la cantidad {quantity} {from_unit} y quieres convertirla a {to_unit}.
                                            Proporci√≥name la cantidad convertida y una breve explicaci√≥n de c√≥mo se realiza la conversi√≥n.
                                            Si no es posible hacer la conversi√≥n, indica un mensaje de error amigable.
                                        """)


        formatted_prompt = prompt.format(quantity=quantity, from_unit=from_unit, to_unit=to_unit)
        respuesta = llm.invoke(formatted_prompt)

        return {"conversion": respuesta}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error en la conversi√≥n: {str(e)}")

# Ejemplo de uso
# {
#   "quantity": 1,
#   "from_unit": "taza",
#   "to_unit": "gramos"
# }




''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Temporadas/Pa√≠ses
@app.post("/comidas_por_temporada/")
async def get_seasonal_foods(request: SeasonalFoodRequest):
    season = request.season.lower()
    country = request.country.lower()

    try:
        llm = HuggingFaceEndpoint(endpoint_url="https://api-inference.huggingface.co/models/microsoft/Phi-3.5-mini-instruct",  
                                  huggingfacehub_api_token=huggingface_api_key,
                                  temperature=0.7,
                                  max_length=300)

        prompt = PromptTemplate(input_variables=["season", "country"],
                                template="""
                                            En el pa√≠s de {country}, ¬øcu√°les son las comidas t√≠picas para la estaci√≥n {season}?
                                            Dame una lista de platos t√≠picos, explicando brevemente qu√© los hace caracter√≠sticos de esta temporada.
                                        """)

        formatted_prompt = prompt.format(season=season, country=country)
        respuesta = llm.invoke(formatted_prompt)

        return {"foods": respuesta}

    except Exception as e:
        # Manejo de errores
        raise HTTPException(status_code=500, detail=f"Error al obtener comidas: {str(e)}")





# ejemplo de uso:
# {
#     "season": "oto√±o",
#     "country": "mexico"
# }
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
#Enfermedades
@app.post("/alergias-enfermedades/")
async def get_food_recommendations(request: HealthConditionRequest):
    condition = request.condition.lower()

    try:
        llm = HuggingFaceEndpoint(endpoint_url="https://api-inference.huggingface.co/models/microsoft/Phi-3.5-mini-instruct",  
                                  huggingfacehub_api_token=huggingface_api_key,  
                                  temperature=0.7,
                                  max_length=300)

        prompt = PromptTemplate(input_variables=["condition"],
                                template="""
                                            Si alguien tiene la condici√≥n de salud llamada '{condition}', ¬øqu√© alimentos debe evitar y qu√© alternativas saludables podr√≠a considerar?
                                            Proporciona una lista de alimentos a evitar y alguna recomendaci√≥n adicional sobre c√≥mo manejar esta condici√≥n con la dieta.
                                        """)

        formatted_prompt = prompt.format(condition=condition)
        respuesta = llm.invoke(formatted_prompt)

        return {"recommendations": respuesta}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Error al obtener recomendaciones: {str(e)}")


# ejemplo de uso:
# {
#     "condition": "cel√≠aco"
# }



''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''''
# Punto de entrada principal
if __name__ == "__main__":
    uvicorn.run(app, host="127.0.0.1", port=8000)
